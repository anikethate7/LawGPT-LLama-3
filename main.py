import streamlit as st
import os
import time
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain_groq import ChatGroq
from langchain.memory import ConversationBufferWindowMemory
from langchain.chains import ConversationalRetrievalChain
from dotenv import load_dotenv

# Import category modules
import consumer
import criminal
import cyber
import property
import KYR

# Load environment variables
load_dotenv()
os.environ['GOOGLE_API_KEY'] = os.getenv("GOOGLE_API_KEY")
groq_api_key = os.getenv("GROQ_API_KEY")

st.set_page_config(page_title="NyayGURU")

# Dictionary of categories
categories = {
    "üìñ Know Your Rights": KYR,
    "‚öñÔ∏è Criminal Law": criminal,
    "üñ•Ô∏è Cyber Law": cyber,
    "üè° Property Law": property,
    "üìú Consumer Law": consumer,
}

# Initialize session state
if "selected_category" not in st.session_state:
    st.session_state.selected_category = list(categories.keys())[0]

if "messages_per_category" not in st.session_state:
    st.session_state.messages_per_category = {category: [] for category in categories.keys()}

# Enhanced Sidebar UI Styling with Gray Tone
st.markdown("""
    <style>
    [data-testid="stSidebar"] {
        width: 280px !important;
        background: linear-gradient(135deg, #f0f0f0, #dcdcdc) !important;
        color: black;
        padding: 20px;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
        border-right: 2px solid rgba(0, 0, 0, 0.1);
    }
    
    @media (prefers-color-scheme: dark) {
        [data-testid="stSidebar"] {
            background: linear-gradient(135deg, #2c2c2c, #3a3a3a) !important;
            color: white;
            border-right: 2px solid rgba(255, 255, 255, 0.1);
        }
    }
    
    .sidebar-title {
        font-size: 26px;
        font-weight: bold;
        text-align: center;
        margin-bottom: 15px;
        padding-bottom: 10px;
        border-bottom: 2px solid rgba(0, 0, 0, 0.2);
    }
    
    @media (prefers-color-scheme: dark) {
        .sidebar-title {
            border-bottom: 2px solid rgba(255, 255, 255, 0.2);
        }
    }
    
    .sidebar-content {
        flex-grow: 1;
        display: flex;
        flex-direction: column;
        gap: 10px;
    }
    
    .sidebar-footer {
        text-align: center;
        font-size: 14px;
        margin-top: 20px;
        padding-top: 10px;
        border-top: 1px solid rgba(0, 0, 0, 0.2);
    }
    
    @media (prefers-color-scheme: dark) {
        .sidebar-footer {
            border-top: 1px solid rgba(255, 255, 255, 0.2);
        }
    }
    </style>
""", unsafe_allow_html=True)

# Sidebar UI
with st.sidebar:
    st.markdown('<div class="sidebar-title">‚öñÔ∏è NyayGURU</div>', unsafe_allow_html=True)

    with st.container():
        st.markdown('<div class="sidebar-content">', unsafe_allow_html=True)
        for idx, category in enumerate(categories.keys()):  # Ensure unique keys
            if st.button(category, use_container_width=True, key=f"button_{idx}"):
                st.session_state.selected_category = category
        st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="sidebar-footer">üõ°Ô∏è Stay legally informed.</div>', unsafe_allow_html=True)


# Function to run chatbot
def run_chatbot():
    current_category = st.session_state.selected_category

    if "memory" not in st.session_state:
        st.session_state.memory = ConversationBufferWindowMemory(k=2, memory_key="chat_history", return_messages=True)

    # Initialize embeddings and vector store
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    db = FAISS.load_local("my_vector_store", embeddings, allow_dangerous_deserialization=True)
    db_retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": 4})

    # Define prompt template
    prompt_template = """
    <s>[INST]This is a chat template. As a legal chatbot, your primary objective is to provide accurate and concise information based on the user's questions. 
    CONTEXT: {context}
    CHAT HISTORY: {chat_history}
    QUESTION: {question}
    ANSWER:
    </s>[INST]
    """
    prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question', 'chat_history'])

    # Initialize LLM
    llm = ChatGroq(groq_api_key=groq_api_key, model_name="llama3-70b-8192")

    # Set up QA chain
    qa = ConversationalRetrievalChain.from_llm(
        llm=llm,
        memory=st.session_state.memory,
        retriever=db_retriever,
        combine_docs_chain_kwargs={'prompt': prompt}
    )

    # Display previous messages for the selected category
    for message in st.session_state.messages_per_category[current_category]:
        with st.chat_message(message.get("role")):
            st.write(message.get("content"))

    # Chat input
    input_prompt = st.chat_input("Ask a legal question...")
    if input_prompt:
        with st.chat_message("user"):
            st.write(input_prompt)
        st.session_state.messages_per_category[current_category].append({"role": "user", "content": input_prompt})

        with st.chat_message("assistant"):
            with st.status("Thinking üí°...", expanded=True):
                result = qa.invoke(input=input_prompt)
                message_placeholder = st.empty()
                full_response = ""

                for chunk in result["answer"]:
                    full_response += chunk
                    time.sleep(0.02)
                    message_placeholder.markdown(full_response + " ‚ñå")

        st.session_state.messages_per_category[current_category].append({"role": "assistant", "content": result["answer"]})

# Call the show function of the selected category
categories[st.session_state.selected_category].show(run_chatbot)
